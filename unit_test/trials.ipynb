{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii\n"
     ]
    }
   ],
   "source": [
    "print(\"hii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sohaib\n"
     ]
    }
   ],
   "source": [
    "print(\"sohaib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Welcome\\\\Desktop\\\\medi-chatbot-'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\Welcome\\Desktop\\medi-chatbot-\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use os.chdir() to change the directory\n",
    "os.chdir(r\"C:\\Users\\Welcome\\Desktop\\medi-chatbot-\")\n",
    "\n",
    "# Verify that the directory has been changed\n",
    "print(\"Current Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Welcome\\\\Desktop\\\\medi-chatbot-'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader , DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data from the PDF file\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob = \"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data = 'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunking operation\n",
    "# split the data into text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap = 20) \n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of text chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Welcome\\AppData\\Local\\Temp\\ipykernel_15592\\3392259316.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "c:\\Users\\Welcome\\Desktop\\medi-chatbot-\\myenv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "#download the embeddings from the hugging face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "#cheking here embedding hua download huahai ya nhi and checking their dimension\n",
    "query_result = embeddings.embed_query(\"hello world\")\n",
    "print(\"Length\", len(query_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking vector\n",
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.environ.get('HUGGINGFACEHUB_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"medi-chatbot2\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Hugging Face API key and pinecone \n",
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Existing index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x27d132b0310>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"what is fever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='94242930-101a-478e-8cfd-95b4cdcc9e1a', metadata={'page': 69.0, 'source': 'Data\\\\Medical_book.pdf'}, page_content='fever in children. This disease is most often caused by\\ntypes 3 and 7. Symptoms, which appear suddenly and\\nusually disappear in less than a week, include:\\n• inflammation of the lining of the eyelid (conjunctivitis)\\n•f e v e r\\n• sore throat (pharyngitis)\\n• runny nose\\n• inflammation of lymph glands in the neck (cervical\\nadenitis)\\nGALE ENCYCLOPEDIA OF MEDICINE 256\\nAdenovirus infections\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 56'),\n",
       " Document(id='5fa1169f-1d39-42db-82ae-5dae54831d06', metadata={'page': 60.0, 'source': 'Data\\\\Medical_book.pdf'}, page_content='(38°–40°C). In addition, a general ill feeling, muscle\\naches,headache, chills, and loss of appetite may be felt.\\nDiagnosis\\nIf lymphangitis is suspected, the person should call\\nhis or her doctor immediately or go to an emergency\\nroom. Acute lymphangitis could be diagnosed by the\\nfamily doctor, infectious disease specialist, or an emer-\\ngency room doctor. The painful, red streaks just below\\nthe skin surface and the high fever are diagnostic of acute'),\n",
       " Document(id='d2dcb7bf-05dc-4e43-8ff9-52f2c85f9d1f', metadata={'page': 618.0, 'source': 'Data\\\\Medical_book.pdf'}, page_content='Description\\nAlso known as undulant fever, Malta fever, Gibraltar\\nfever, Bang’s disease, or Mediterranean fever, brucellosis\\nis most likely to occur among those individuals who reg-\\nularly work with livestock. The disease originated in\\ndomestic livestock but was passed on to wild animal\\nspecies, including the elk and buffalo of the western\\nUnited States. In humans, brucellosis continues to be\\nspread via unpasteurized milk obtained from infected')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs\n",
    "#this dont give the complete answer that's why we need to llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Welcome\\AppData\\Local\\Temp\\ipykernel_15592\\3725394950.py:19: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Hugging Face LLM\n",
    "# Initialize LLM\n",
    "\n",
    "# Hugging Face Hub ke liye free model configuration\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_new_tokens\": 250,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# System prompt\n",
    "system_prompt = (\n",
    "    \"You are a highly knowledgeable assistant tasked with providing detailed and accurate answers. \"\n",
    "    \"For the given query, please answer in detail, covering all aspects of the topic. \"\n",
    "    \"If the query asks for multiple components (e.g., causes, symptoms, treatments), provide a thorough breakdown for each. \"\n",
    "    \"Be as detailed as possible within the token limit, and ensure that you give examples where applicable. \"\n",
    "    \"Always reference the retrieved context when answering, and if more information is needed, request clarification politely. \"\n",
    "    \"If the information in the context is insufficient, clearly state that and ask for further details.\"\n",
    "    \"\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain for generating responses\n",
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain = create_retrieval_chain(retriever,question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1—The cancer is no larger than 2 cm (0.8 in) and no cancer cells are found in the lymph nodes. Stage 2—The cancer is between 2 cm and 5 cm, and the cancer has spread to the lymph nodes. Stage 3A—Tumor is larger than 5 cm (2 in) or is small- er than 5 cm, but has spread to the lymph nodes, which have grown into each other. Stage 3B—Cancer has spread to tissues near the breast, (local invasion), or to lymph nodes inside the chest it often becomes systemic or widespread early in the course of the disease. By the time one can feel a lump in the breast it is often 0.4 inches, or one centimeter, in size and contains roughly a million cells.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"early stages of cancer?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
